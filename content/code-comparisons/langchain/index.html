<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2025-06-23T03:13:35+00:00" /><link rel="index" title="Index" href="../../genindex/" /><link rel="search" title="Search" href="../../search/" /><link rel="next" title="Airflow" href="../airflow/" /><link rel="prev" title="Dagster" href="../dagster/" />
        <link rel="canonical" href="https://hamilton.staged.apache.org/code-comparisons/langchain/" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>LangChain - Hamilton</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/testimonials.css?v=bd684830" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-announcement-background: #ffba00;
  --color-announcement-text: #091E42;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-announcement-background: #ffba00;
  --color-announcement-text: #091E42;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-announcement-background: #ffba00;
  --color-announcement-text: #091E42;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     📢 Announcing the <a target="_blank" href="https://www.meetup.com/global-hamilton-open-source-user-group-meetup/">Hamilton Meetup Group</a>. Sign up to attend events! 📢 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../"><div class="brand">Hamilton</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../">
  
  
  <span class="sidebar-brand-text">Hamilton</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search/" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">USER GUIDE</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../get-started/">Get Started</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Get Started</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/why-hamilton/">Why use Apache Hamilton?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/install/">Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/your-first-dataflow/">Your First Dataflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/learning-resources/">Learning Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/contributing/">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get-started/license/">License</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../concepts/">Concepts</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Concepts</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/glossary/">Glossary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/node/">Functions, nodes &amp; dataflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/driver/">Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/visualization/">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/materialization/">Materialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/function-modifiers/">Function modifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/builder/">Builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/caching/">Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/function-modifiers-advanced/">Function modifiers (Advanced)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/parallel-task/">Dynamic DAGs/Parallel Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/">UI Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/#local-mode">Local Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/#docker-deployed-mode">Docker/Deployed Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/#get-started">Get started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concepts/ui/#sdk-configuration">SDK Configuration</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../concepts/best-practices/">Best Practices</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Best Practices</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/function-naming/">Function Naming</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/migrating-to-hamilton/">Migrating to Apache Hamilton</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/code-organization/">Code Organization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/common-indices/">Common Indices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/output-immutability/">Output Immutability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/using-within-your-etl-system/">Using within your ETL System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../concepts/best-practices/loading-data/">Loading Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how-tos/">User Guide</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of User Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/use-in-jupyter-notebook/">Jupyter notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/load-data/">Loading data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/caching-tutorial/">Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/use-for-feature-engineering/">Feature engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/ml-training/">Model training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/llm-workflows/">LLM workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/run-data-quality-checks/">Data quality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/use-hamilton-for-lineage/">Lineage + Apache Hamilton</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/scale-up/">Scaling computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/microservice/">Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/extensions-autoloading/">Extension autoloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/wrapping-driver/">Wrapping the Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/cli-reference/">Command line interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-tos/pre-commit-hooks/">pre-commit hooks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hamilton-ui/">Apache Hamilton UI</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Apache Hamilton UI</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/">UI Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/#local-mode">Local Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/#docker-deployed-mode">Docker/Deployed Mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/#get-started">Get started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-ui/ui/#sdk-configuration">SDK Configuration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../hamilton-vscode/">IDE extension</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of IDE extension</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-vscode/vscode_extension/">Apache Hamilton VSCode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hamilton-vscode/language_server/">Language Server</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../integrations/">Integrations</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Integrations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../integrations/dlt/">dlt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../integrations/fastapi/">FastAPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../integrations/ibis/">Ibis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../integrations/streamlit/">Streamlit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../integrations/dbt/">dbt</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/mlflow">MLFlow</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/airflow">Airflow</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/aws">Amazon Web Services</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/LLM_Workflows/image_telephone">Burr</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/dagster">Dagster</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/dask">Dask</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/feast">Feast</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/outerbounds/hamilton-metaflow">Metaflow</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/data_quality/pandera">Pandera</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/plotly">Plotly</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/polars">Polars</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/prefect">Prefect</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/ray">Ray</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/slack">Slack</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/spark">Spark</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/vaex">Vaex</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/narwhals">Narwhals</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/apache/hamilton/tree/main/examples/openlineage">OpenLineage</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../">Code Comparisons</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Code Comparisons</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../kedro/">Kedro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dagster/">Dagster</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">LangChain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../airflow/">Airflow</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PDF</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://hamilton.apache.org/_static/Hamilton.pdf">PDF</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/">Meet-ups</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/hamilton-opensource/shared_invite/zt-2niepkra8-DGKGf_tTYhXuJWBTXtIs4g">Slack</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">REFERENCE</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/decorators/">Decorators</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Decorators</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/check_output/">check_output*</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/config_when/">config.when*</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/dataloader/">dataloader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/datasaver/">datasaver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/does/">does</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/extract_columns/">extract_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/extract_fields/">extract_fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/inject/">inject</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/load_from/">load_from</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize/">parameterize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize_extract_columns/">parameterize_extract_columns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize_frame/">parameterize_frame</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize_sources/">parameterize_sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize_subdag/">parameterized_subdag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/parameterize_values/">parameterize_values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/pipe/">pipe family</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/resolve/">resolve</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/save_to/">save_to</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/subdag/">subdag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/schema/">schema</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/tag/">tag*</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/decorators/with_columns/">with_columns</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/drivers/">Drivers</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Drivers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/Driver/">Builder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/Driver/#driver">Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/Driver/#defaultgraphexecutor">DefaultGraphExecutor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/Driver/#taskbasedgraphexecutor">TaskBasedGraphExecutor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/AsyncDriver/">AsyncDriver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/drivers/Custom/">Custom Driver</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/caching/">Caching</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Caching</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/caching/caching-logic/">Caching logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/caching/data-versioning/">Data versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/caching/stores/">Stores</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/graph-adapters/">GraphAdapters</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of GraphAdapters</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/SimplePythonDataFrameGraphAdapter/">SimplePythonDataFrameGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/SimplePythonGraphAdapter/">SimplePythonGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/HamiltonGraphAdapter/">HamiltonGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/AsyncGraphAdapter/">h_async.AsyncGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/ThreadPoolFutureAdapter/">h_threadpool.FutureAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/CachingGraphAdapter/">CachingGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/DaskGraphAdapter/">h_dask.DaskGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/PySparkUDFGraphAdapter/">h_spark.PySparkUDFGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/RayGraphAdapter/">h_ray.RayGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/RayWorkflowGraphAdapter/">h_ray.RayWorkflowGraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/graph-adapters/SparkKoalasGraphAdapter/">h_spark.SparkKoalasGraphAdapter</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/lifecycle-hooks/">Lifecycle Adapters</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Lifecycle Adapters</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/ResultBuilder/">lifecycle.ResultBuilder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/LegacyResultMixin/">lifecycle.LegacyResultMixin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/GraphAdapter/">lifecycle.api.GraphAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/NodeExecutionHook/">lifecycle.NodeExecutionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/GraphExecutionHook/">lifecycle.api.GraphExecutionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/EdgeConnectionHook/">lifecycle.api.EdgeConnectionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/NodeExecutionMethod/">lifecycle.api.NodeExecutionMethod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/StaticValidator/">lifecycle.api.StaticValidator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/GraphConstructionHook/">lifecycle.api.GraphConstructionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/TaskSubmissionHook/">lifecycle.api.TaskSubmissionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/TaskReturnHook/">lifecycle.api.TaskReturnHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/TaskExecutionHook/">lifecycle.api.TaskExecutionHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/TaskGroupingHook/">lifecycle.api.TaskGroupingHook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/PDBDebugger/">lifecycle.PDBDebugger</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/PrintLn/">lifecycle.PrintLn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/ProgressBar/">plugins.h_tqdm.ProgressBar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/RichProgressBar/">plugins.h_rich.RichProgressBar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/DDOGTracer/">plugins.h_ddog.DDOGTracer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/FunctionInputOutputTypeChecker/">lifecycle.FunctionInputOutputTypeChecker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/SlackNotifierHook/">plugins.h_slack.SlackNotifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/GracefulErrorAdapter/">lifecycle.GracefulErrorAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/SparkInputValidator/">plugins.h_spark.SparkInputValidator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/Narwhals/">plugins.h_narhwals.NarwhalsAdapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/Narwhals/#plugins-h-narhwals-narwhalsdataframeresultbuilder">plugins.h_narhwals.NarwhalsDataFrameResultBuilder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/MLFlowTracker/">plugins.h_mlflow.MLFlowTracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/NoEdgeAndInputTypeChecking/">lifecycle.NoEdgeAndInputTypeChecking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/lifecycle-hooks/OpenLineageAdapter/">plugins.h_openlineage.OpenLineageAdapter</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/result-builders/">ResultBuilders</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of ResultBuilders</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Generic/">Generic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Numpy/">Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Pandas/">Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Polars/">Polars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Dask/">Dask</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/result-builders/Custom/">Custom ResultBuilder</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/io/">I/O</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of I/O</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/io/available-data-adapters/">Using Data Adapters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/io/available-data-adapters/#data-loaders">Data Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/io/available-data-adapters/#data-savers">Data Savers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/io/adapter-documentation/">Data Adapters</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reference/dataflows/">Dataflows</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Dataflows</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/clear_storage/">clear_storage()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/copy/">copy()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/find/">find()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/import_module/">import_module()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/inspect/">inspect()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/inspect_module/">inspect_module()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/install_dependencies_string/">install_dependencies_string()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/latest_commit/">latest_commit()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/list/">list()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reference/dataflows/pull_module/">pull_module()</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/disabling-telemetry/">Telemetry</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">EXTERNAL RESOURCES</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apache/hamilton">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.tryhamilton.dev/">tryhamilton.dev</a></li>
<li class="toctree-l1"><a class="reference external" href="https://hub.dagworks.io/docs/">Dataflow Hub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://blog.dagworks.io/">Blog</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/apache/hamilton/blob/main/docs/code-comparisons/langchain.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div><div class="edit-this-page">
  <a class="muted-link" href="https://github.com/apache/hamilton/edit/main/docs/code-comparisons/langchain.rst" title="Edit this page">
    <svg><use href="#svg-pencil"></use></svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="langchain">
<h1>LangChain<a class="headerlink" href="#langchain" title="Link to this heading">¶</a></h1>
<p>Here we have some code snippets that help compare a vanilla code implementation
with LangChain and Apache Hamilton.</p>
<p>LangChain’s focus is on hiding details and making code terse.</p>
<p>Apache Hamilton’s focus instead is on making code more readable, maintainable, and importantly customizeable.</p>
<p>So don’t be surprised that Apache Hamilton’s code is “longer” - that’s by design. There is
also little abstraction between you, and the underlying libraries with Apache Hamilton.
With LangChain they’re abstracted away, so you can’t really see easily what’s going on
underneath.</p>
<p><em>Rhetorical question</em>: which code would you rather maintain, change, and update?</p>
<section id="a-simple-joke-example">
<h2>A simple joke example<a class="headerlink" href="#a-simple-joke-example" title="Link to this heading">¶</a></h2>
<div class="table-wrapper docutils container" id="id1">
<table class="docutils align-left" id="id1">
<caption><span class="caption-text">Simple Invocation</span><a class="headerlink" href="#id1" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_invoke.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>


<span class="k">def</span><span class="w"> </span><span class="nf">llm_client</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Tell me a short joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_messages</span><span class="p">(</span><span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">joke_prompt</span><span class="p">}]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_response</span><span class="p">(</span><span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
                  <span class="n">joke_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">joke_messages</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_invoke</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_invoke</span><span class="p">)</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span><span class="s2">&quot;hamilton-invoke.png&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">([</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
                     <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_chat_model</span><span class="p">(</span><span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">def</span><span class="w"> </span><span class="nf">invoke_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt_value</span><span class="p">}]</span>
    <span class="k">return</span> <span class="n">call_chat_model</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">invoke_chain</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="../../_images/hamilton-invoke.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-invoke.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized.</span><a class="headerlink" href="#id2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="a-streamed-joke-example">
<h2>A streamed joke example<a class="headerlink" href="#a-streamed-joke-example" title="Link to this heading">¶</a></h2>
<p>With Apache Hamilton we can just swap the call function to return a streamed response.
Note: you could use &#64;config.when to include both streamed and non-streamed versions in the same DAG.</p>
<div class="table-wrapper docutils container" id="id3">
<table class="docutils align-left" id="id3">
<caption><span class="caption-text">Streamed Version</span><a class="headerlink" href="#id3" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_streamed.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>


<span class="k">def</span><span class="w"> </span><span class="nf">llm_client</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Tell me a short joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_messages</span><span class="p">(</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">joke_prompt</span><span class="p">}]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_response</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
        <span class="n">joke_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">joke_messages</span><span class="p">,</span>
        <span class="n">stream</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span>
        <span class="k">if</span> <span class="n">content</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">content</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_streaming</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_streaming</span><span class="p">)</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span>
        <span class="s2">&quot;hamilton-streaming.png&quot;</span>
    <span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterator</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">stream_chat_model</span><span class="p">(</span>
        <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span>
        <span class="k">if</span> <span class="n">content</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">content</span>


<span class="k">def</span><span class="w"> </span><span class="nf">stream_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">stream_chat_model</span><span class="p">(</span>
        <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt_value</span><span class="p">}])</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">stream_chain</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>


<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chain</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="../../_images/hamilton-streamed.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-streamed.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized.</span><a class="headerlink" href="#id4" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="a-batch-parallel-joke-example">
<h2>A “batch” parallel joke example<a class="headerlink" href="#a-batch-parallel-joke-example" title="Link to this heading">¶</a></h2>
<p>In this batch example, the joke requests are parallelized.
Note: with Apache Hamilton you can delegate to many different backends for parallelization,
e.g. Ray, Dask, etc. We use multi-threading here.</p>
<div class="table-wrapper docutils container" id="id5">
<table class="docutils align-left" id="id5">
<caption><span class="caption-text">Batch Parallel Version</span><a class="headerlink" href="#id5" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_batch.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton.execution</span><span class="w"> </span><span class="kn">import</span> <span class="n">executors</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton.htypes</span><span class="w"> </span><span class="kn">import</span> <span class="n">Collect</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton.htypes</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallelizable</span>


<span class="k">def</span><span class="w"> </span><span class="nf">llm_client</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">topic</span><span class="p">(</span>
        <span class="n">topics</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Parallelizable</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">_topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">_topic</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Tell me a short joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_messages</span><span class="p">(</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">joke_prompt</span><span class="p">}]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_response</span><span class="p">(</span><span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
                  <span class="n">joke_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">joke_messages</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_responses</span><span class="p">(</span>
        <span class="n">joke_response</span><span class="p">:</span> <span class="n">Collect</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">joke_response</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_batch</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_batch</span><span class="p">)</span>
        <span class="o">.</span><span class="n">enable_dynamic_execution</span><span class="p">(</span>
            <span class="n">allow_experimental_mode</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">with_remote_executor</span><span class="p">(</span>
            <span class="n">executors</span><span class="o">.</span><span class="n">MultiThreadingExecutor</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span><span class="s2">&quot;hamilton-batch.png&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_responses&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;topics&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;ice cream&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;spaghetti&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;dumplings&quot;</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># can still run single chain with overrides</span>
    <span class="c1"># and getting just one response</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">overrides</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;lettuce&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>


<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_chat_model</span><span class="p">(</span><span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">def</span><span class="w"> </span><span class="nf">invoke_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt_value</span><span class="p">}]</span>
    <span class="k">return</span> <span class="n">call_chat_model</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">batch_chain</span><span class="p">(</span><span class="n">topics</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">invoke_chain</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
        <span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">batch_chain</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;ice cream&quot;</span><span class="p">,</span> <span class="s2">&quot;spaghetti&quot;</span><span class="p">,</span> <span class="s2">&quot;dumplings&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;ice cream&quot;</span><span class="p">,</span>
             <span class="s2">&quot;spaghetti&quot;</span><span class="p">,</span>
             <span class="s2">&quot;dumplings&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="../../_images/hamilton-batch.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-batch.png" style="width: 75%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized.</span><a class="headerlink" href="#id6" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="a-async-joke-example">
<h2>A “async” joke example<a class="headerlink" href="#a-async-joke-example" title="Link to this heading">¶</a></h2>
<p>Here we show how to make the joke using async constructs. With Apache Hamilton
you can mix and match async and regular functions, the only change
is that you need to use the async Apache Hamilton Driver.</p>
<div class="table-wrapper docutils container" id="id7">
<table class="docutils align-left" id="id7">
<caption><span class="caption-text">Async Version</span><a class="headerlink" href="#id7" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_async.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>


<span class="k">def</span><span class="w"> </span><span class="nf">llm_client</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Tell me a short joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_messages</span><span class="p">(</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">joke_prompt</span><span class="p">}]</span>


<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">joke_response</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">,</span>
        <span class="n">joke_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="p">(</span>
        <span class="n">llm_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">joke_messages</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>

    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_async</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">base</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">async_driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="n">async_driver</span><span class="o">.</span><span class="n">AsyncDriver</span><span class="p">(</span>
        <span class="p">{},</span>
        <span class="n">hamilton_async</span><span class="p">,</span>
        <span class="n">result_builder</span><span class="o">=</span><span class="n">base</span><span class="o">.</span><span class="n">DictResult</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span><span class="s2">&quot;hamilton-async.png&quot;</span><span class="p">)</span>
    <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>


<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="n">async_client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">()</span>

<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">acall_chat_model</span><span class="p">(</span>
        <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="p">(</span>
        <span class="n">async_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>

<span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">ainvoke_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">topic</span><span class="o">=</span><span class="n">topic</span>
    <span class="p">)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt_value</span><span class="p">}]</span>
    <span class="k">return</span> <span class="k">await</span> <span class="n">acall_chat_model</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>

    <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
        <span class="n">ainvoke_chain</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
    <span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span>
        <span class="n">chain</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="../../_images/hamilton-async.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-async.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized.</span><a class="headerlink" href="#id8" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="switch-llm-to-completion-for-joke">
<h2>Switch LLM to completion for joke<a class="headerlink" href="#switch-llm-to-completion-for-joke" title="Link to this heading">¶</a></h2>
<p>Here we show how to make the joke switching to a different openAI model that is for completion.
Note: we use the &#64;config.when construct to augment the original DAG and add a new function
that uses the different OpenAI model.</p>
<div class="table-wrapper docutils container" id="id9">
<table class="docutils align-left" id="id9">
<caption><span class="caption-text">Completion Version</span><a class="headerlink" href="#id9" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_completion.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton.function_modifiers</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>


<span class="k">def</span><span class="w"> </span><span class="nf">llm_client</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Tell me a short joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_messages</span><span class="p">(</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">joke_prompt</span><span class="p">}]</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;completion&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">joke_response__completion</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">joke_prompt</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;chat&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">joke_response__chat</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
        <span class="n">joke_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">joke_messages</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_completion</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_completion</span><span class="p">)</span>
        <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;completion&quot;</span><span class="p">})</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span>
        <span class="s2">&quot;hamilton-completion.png&quot;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_completion</span><span class="p">)</span>
        <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;chat&quot;</span><span class="p">})</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span><span class="s2">&quot;hamilton-chat.png&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_llm</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt_value</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>

<span class="k">def</span><span class="w"> </span><span class="nf">invoke_llm_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">call_llm</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">)</span>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">invoke_llm_chain</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">)</span>
<span class="n">llm_chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">llm</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="../../_images/hamilton-completion.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-completion.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized with configuration provided for the completion path. Note the dangling node - that’s normal, it’s not used in the completion path.</span><a class="headerlink" href="#id10" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="switch-to-using-anthropic">
<h2>Switch to using Anthropic<a class="headerlink" href="#switch-to-using-anthropic" title="Link to this heading">¶</a></h2>
<p>Here we show how to make the joke switching to use a different model provider, in this case
it’s Anthropic.
Note: we use the &#64;config.when construct to augment the original DAG and add a new functions
to use Anthropic.</p>
<div class="table-wrapper docutils container" id="id11">
<table class="docutils align-left" id="id11">
<caption><span class="caption-text">Anthropic Version</span><a class="headerlink" href="#id11" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># hamilton_anthropic.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">anthropic</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">openai</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton.function_modifiers</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">llm_client__openai</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">()</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;anthropic&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">llm_client__anthropic</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">Anthropic</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">Anthropic</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">joke_prompt</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="s2">&quot;Human:</span><span class="se">\n\n</span><span class="s2">&quot;</span> 
        <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="se">\n\n</span><span class="s2">&quot;</span>
        <span class="s2">&quot;Assistant:&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">joke_response__openai</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">,</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">joke_prompt</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>


<span class="nd">@config</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">provider</span><span class="o">=</span><span class="s2">&quot;anthropic&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">joke_response__anthropic</span><span class="p">(</span>
        <span class="n">llm_client</span><span class="p">:</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">Anthropic</span><span class="p">,</span>
        <span class="n">joke_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">joke_prompt</span><span class="p">,</span>
        <span class="n">max_tokens_to_sample</span><span class="o">=</span><span class="mi">256</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">completion</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_invoke_anthropic</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_invoke_anthropic</span><span class="p">)</span>
        <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span> <span class="s2">&quot;anthropic&quot;</span><span class="p">})</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">display_all_functions</span><span class="p">(</span>
        <span class="s2">&quot;hamilton-anthropic.png&quot;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
        <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_invoke_anthropic</span><span class="p">)</span>
        <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">})</span>
        <span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">anthropic</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">anthropic_template</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Human:</span><span class="se">\n\n</span><span class="si">{</span><span class="n">prompt_template</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Assistant:&quot;</span>
<span class="n">anthropic_client</span> <span class="o">=</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">Anthropic</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_anthropic</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">anthropic_client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt_value</span><span class="p">,</span>
        <span class="n">max_tokens_to_sample</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">completion</span>


<span class="k">def</span><span class="w"> </span><span class="nf">invoke_anthropic_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">anthropic_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">call_anthropic</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">invoke_anthropic_chain</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAnthropic</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">anthropic</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">)</span>
<span class="n">anthropic_chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">anthropic</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">anthropic_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<figure class="align-center" id="id12">
<a class="reference internal image-reference" href="../../_images/hamilton-anthropic.png"><img alt="Structure of the Apache Hamilton DAG" src="../../_images/hamilton-anthropic.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-text">The Apache Hamilton DAG visualized with configuration provided to use Anthropic.</span><a class="headerlink" href="#id12" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="logging">
<h2>Logging<a class="headerlink" href="#logging" title="Link to this heading">¶</a></h2>
<p>Here we show how to log more information about the joke request. Apache Hamilton has
lots of customization options, and one out of the box is to log more information via
printing.</p>
<div class="table-wrapper docutils container" id="id13">
<table class="docutils align-left" id="id13">
<caption><span class="caption-text">Logging</span><a class="headerlink" href="#id13" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># run.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span><span class="p">,</span> <span class="n">lifecycle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_anthropic</span>

<span class="n">dr</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
    <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_anthropic</span><span class="p">)</span>
    <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span> <span class="s2">&quot;anthropic&quot;</span><span class="p">})</span>
    <span class="c1"># we just need to add this line to get things printing</span>
    <span class="c1"># to the console; see DAGWorks for a more off-the-shelf</span>
    <span class="c1"># solution.</span>
    <span class="o">.</span><span class="n">with_adapters</span><span class="p">(</span><span class="n">lifecycle</span><span class="o">.</span><span class="n">PrintLn</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">dr</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
        <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">anthropic</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span>
<span class="n">anthropic_template</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Human:</span><span class="se">\n\n</span><span class="si">{</span><span class="n">prompt_template</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Assistant:&quot;</span>
<span class="n">anthropic_client</span> <span class="o">=</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">Anthropic</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">call_anthropic</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">anthropic_client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt_value</span><span class="p">,</span>
        <span class="n">max_tokens_to_sample</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">completion</span>


<span class="k">def</span><span class="w"> </span><span class="nf">invoke_anthropic_chain_with_logging</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">prompt_value</span> <span class="o">=</span> <span class="n">anthropic_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="o">=</span><span class="n">topic</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Formatted prompt: </span><span class="si">{</span><span class="n">prompt_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">call_anthropic</span><span class="p">(</span><span class="n">prompt_value</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">invoke_anthropic_chain_with_logging</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAnthropic</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">anthropic</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">)</span>
<span class="n">anthropic_chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">anthropic</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LANGCHAIN_TRACING_V2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;true&quot;</span>
    <span class="c1"># it&#39;s hard to customize the logging output of langchain</span>
    <span class="c1"># so here&#39;s their way to try to make money from you!</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">anthropic_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="fallbacks">
<h2>Fallbacks<a class="headerlink" href="#fallbacks" title="Link to this heading">¶</a></h2>
<p>Fallbacks are pretty situation and context dependent. It’s not that
hard to wrap a function in a try/except block. The key is to make sure
you know what’s going on, and that a fallback was triggered. So in our
opinion it’s better to be explicit about it.</p>
<div class="table-wrapper docutils container" id="id14">
<table class="docutils align-left" id="id14">
<caption><span class="caption-text">Logging</span><a class="headerlink" href="#id14" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Apache Hamilton</p></th>
<th class="head"><p>Vanilla</p></th>
<th class="head"><p>LangChain</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hamilton_anthropic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hamilton</span><span class="w"> </span><span class="kn">import</span> <span class="n">driver</span>

<span class="n">anthropic_driver</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
    <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_anthropic</span><span class="p">)</span>
    <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span> <span class="s2">&quot;anthropic&quot;</span><span class="p">})</span>
    <span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">openai_driver</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">driver</span><span class="o">.</span><span class="n">Builder</span><span class="p">()</span>
    <span class="o">.</span><span class="n">with_modules</span><span class="p">(</span><span class="n">hamilton_anthropic</span><span class="p">)</span>
    <span class="o">.</span><span class="n">with_config</span><span class="p">({</span><span class="s2">&quot;provider&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">})</span>
    <span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">anthropic_driver</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="c1"># this is the current way to do fall backs</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">openai_driver</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;joke_response&quot;</span><span class="p">],</span>
            <span class="n">inputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;ice cream&quot;</span><span class="p">}</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">invoke_chain_with_fallback</span><span class="p">(</span><span class="n">topic</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">invoke_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>  <span class="c1"># noqa: F821</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">invoke_anthropic_chain</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>  <span class="c1"># noqa: F821</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">invoke_chain_with_fallback</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
<td><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAnthropic</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">&quot;Tell me a short joke about </span><span class="si">{topic}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">anthropic</span> <span class="o">=</span> <span class="n">ChatAnthropic</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;claude-2&quot;</span><span class="p">)</span>
<span class="n">anthropic_chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">anthropic</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">model</span>
    <span class="o">|</span> <span class="n">output_parser</span>
<span class="p">)</span>

<span class="n">fallback_chain</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">with_fallbacks</span><span class="p">([</span><span class="n">anthropic_chain</span><span class="p">])</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">fallback_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;ice cream&quot;</span><span class="p">))</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../airflow/">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Airflow</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../dagster/">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Dagster</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            <div class="last-updated">
              Last updated on Jun 23, 2025</div>
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">LangChain</a><ul>
<li><a class="reference internal" href="#a-simple-joke-example">A simple joke example</a></li>
<li><a class="reference internal" href="#a-streamed-joke-example">A streamed joke example</a></li>
<li><a class="reference internal" href="#a-batch-parallel-joke-example">A “batch” parallel joke example</a></li>
<li><a class="reference internal" href="#a-async-joke-example">A “async” joke example</a></li>
<li><a class="reference internal" href="#switch-llm-to-completion-for-joke">Switch LLM to completion for joke</a></li>
<li><a class="reference internal" href="#switch-to-using-anthropic">Switch to using Anthropic</a></li>
<li><a class="reference internal" href="#logging">Logging</a></li>
<li><a class="reference internal" href="#fallbacks">Fallbacks</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=187304be"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    </body>
</html>